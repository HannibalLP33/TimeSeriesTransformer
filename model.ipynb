{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "from tensorflow.keras.layers import Lambda, Reshape, Concatenate, Add, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D, Layer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "logging.basicConfig(filename = \"logs.log\", format = \"%(asctime)s -- %(message)s\", datefmt='%m/%d/%Y %I:%M:%S %p', level = logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Upload successfully\n",
      "X training set shape:(442920, 10)\n",
      "y training set shape:(442920,)\n",
      "X test set shape:(110731, 10)\n",
      "y test set shape:(110731,)\n"
     ]
    }
   ],
   "source": [
    "### Load_Data ###\n",
    "training_data = pd.read_csv(\"training_data/10sequence.csv\")\n",
    "training_data.head()\n",
    "X = training_data.iloc[:,:10]\n",
    "y = training_data.iloc[:,10]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = False)\n",
    "\n",
    "logging.info(\"Dataset Upload successfully\")\n",
    "logging.info(f\"X training set shape:{X_train.shape}\")\n",
    "logging.info(f\"y training set shape:{y_train.shape}\")\n",
    "logging.info(f\"X test set shape:{X_test.shape}\")\n",
    "logging.info(f\"y test set shape:{y_test.shape}\")\n",
    "\n",
    "\n",
    "print(\"Dataset Upload successfully\")\n",
    "print(f\"X training set shape:{X_train.shape}\")\n",
    "print(f\"y training set shape:{y_train.shape}\")\n",
    "print(f\"X test set shape:{X_test.shape}\")\n",
    "print(f\"y test set shape:{y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 15:17:51.674745: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "### Global Variables ####\n",
    "sequence_len = 10 # Looking at 24 hours worth of data to determine\n",
    "epochs = 100\n",
    "attention_heads = 6\n",
    "projection_dim = sequence_len\n",
    "dropout = 0.1\n",
    "num_transformer_blocks = 8\n",
    "mlp_units = [2048, 1024, 500, 250, 100, 10]\n",
    "tranformer_mlp_units = [projection_dim ** 2, projection_dim * 2]\n",
    "\n",
    "\n",
    "X_train = tf.expand_dims(X_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5000, 1, 10), dtype=float32, numpy=\n",
       "array([[[-0.07681987, -0.04576923,  0.04169796, ..., -0.01934507,\n",
       "         -0.06159167, -0.01717032]],\n",
       "\n",
       "       [[-0.08798409, -0.05365489,  0.04059355, ..., -0.01711817,\n",
       "         -0.07210016, -0.01813994]],\n",
       "\n",
       "       [[-0.08125924, -0.04890528,  0.0412588 , ..., -0.01845957,\n",
       "         -0.06577118, -0.01755588]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.06488314, -0.03733478,  0.04287872, ..., -0.02172596,\n",
       "         -0.05034851, -0.01613359]],\n",
       "\n",
       "       [[-0.05202583, -0.02824689,  0.04415048, ..., -0.02429033,\n",
       "         -0.03823116, -0.01501689]],\n",
       "\n",
       "       [[-0.06426544, -0.03689824,  0.04293982, ..., -0.02184916,\n",
       "         -0.04976652, -0.01607994]]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Convert time to a vector that can be encoded to the features ###\n",
    "class Time2Vector(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernal: int = 64):\n",
    "        super().__init__(trainable = True,  name = \"Time2VecLayer\")\n",
    "        self.kernal = kernal - 1\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        ### Time to Vector Piecewise function ###\n",
    "        \n",
    "        self.weights_linear = self.add_weight(shape = (input_shape[1],1), initializer = \"uniform\", trainable = True, name = \"weights_linear\")\n",
    "        \n",
    "        self.bias_linear = self.add_weight(shape = (input_shape[1],1), initializer = \"uniform\", trainable = True, name = \"bias_linear\")\n",
    "        \n",
    "        self.weights_periodic = self.add_weight(shape = (input_shape[1], self.kernal), initializer = \"uniform\", trainable = True, name = \"weights_periodic\")\n",
    "        \n",
    "        self.bias_periodic = self.add_weight(shape = (input_shape[1], self.kernal), initializer = \"uniform\", trainable = True, name = \"bias_periodic\")\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = tf.expand_dims(x[:,:,0], axis = -1)\n",
    "        time_linear = (self.weights_linear * x) + self.bias_linear\n",
    "        # time_linear = tf.expand_dims(time_linear, axis = -1) #Expand dimensions to concat later\n",
    "        \n",
    "        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "        # time_periodic = tf.expand_dims(time_periodic, axis = -1)\n",
    "        \n",
    "        final_product = tf.concat([time_linear, time_periodic], axis = -1)\n",
    "        # final_product = tf.expand_dims(final_product, axis = 0)\n",
    "        return final_product\n",
    "    \n",
    "###Test Input###    \n",
    "test_input = tf.random.uniform(shape = (5000, 1, 10), dtype = tf.float32)\n",
    "exampleTV = Time2Vector(10)(test_input)\n",
    "exampleTV\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mlp_block(x, units):\n",
    "    x = GlobalAveragePooling1D(data_format = \"channels_first\")(x)\n",
    "    for unit in units:\n",
    "        x = Dense(unit, activation = tf.nn.gelu)(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "    return x\n",
    "def transformer_encoder(inputs, attention_heads, projection_dim, dropout):\n",
    "    ### Layer Normalization / Multihead Attention Layers ###\n",
    "    x = LayerNormalization(epsilon = 1e-6)(inputs)\n",
    "    x = MultiHeadAttention(num_heads = attention_heads, key_dim = projection_dim, dropout = dropout)(x,x)\n",
    "    skip1 = Add()([x, inputs])\n",
    "    \n",
    "    ### Feed Forward ###\n",
    "    x = LayerNormalization(epsilon = 1e-6)(skip1)\n",
    "    x = mlp_block(x, tranformer_mlp_units)\n",
    "    skip2 = Add()([x,skip1])\n",
    "    \n",
    "    return skip2\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    input = Input(shape = X_train.shape[1:]) # (Batch_size, Sequence Length, Number of Features)\n",
    "    x = Time2Vector(sequence_len)(input)\n",
    "    x = Concatenate(axis = -1)([input, x]) \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, attention_heads, projection_dim, dropout)\n",
    "    x = mlp_block(x, mlp_units)\n",
    "    output = Dense(1, activation = \"relu\")(x)\n",
    "    \n",
    "    model = Model(inputs = input, outputs = output)\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model):\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=1e-3, decay = 1e-4)\n",
    "    checkpoint_path = \"/models/\"\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss = tf.keras.losses.MeanAbsoluteError(), \n",
    "                  metrics = [tf.keras.metrics.MeanSquaredError(name = \"MSE\"), \n",
    "                             tf.keras.metrics.RootMeanSquaredError(name = \"RMSE\"),\n",
    "                             tf.keras.metrics.MeanAbsoluteError(name = \"MAE\")])\n",
    "    \n",
    "    history = model.fit(\n",
    "        x = X_train,\n",
    "        y = y_train,\n",
    "        epochs = epochs,\n",
    "        batch_size = X_train.shape[0],\n",
    "        validation_split = 0.2\n",
    "        \n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 10)]      0           []                               \n",
      "                                                                                                  \n",
      " Time2VecLayer (Time2Vector)    (None, 1, 10)        20          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1, 20)        0           ['input_1[0][0]',                \n",
      "                                                                  'Time2VecLayer[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 1, 20)       40          ['concatenate[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 1, 20)       5000        ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 1, 20)        0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 1, 20)       40          ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 1)           0           ['layer_normalization_1[0][0]']  \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          200         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 20)           2020        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 20)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 1, 20)        0           ['dropout_1[0][0]',              \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 1, 20)       40          ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 1, 20)       5000        ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 1, 20)        0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 1, 20)       40          ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 1)           0           ['layer_normalization_3[0][0]']  \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          200         ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 20)           2020        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 20)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1, 20)        0           ['dropout_3[0][0]',              \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 1, 20)       40          ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 1, 20)       5000        ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 1, 20)        0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 1, 20)       40          ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 1)           0           ['layer_normalization_5[0][0]']  \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 100)          200         ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 100)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 20)           2020        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 20)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 1, 20)        0           ['dropout_5[0][0]',              \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 1, 20)       40          ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 1, 20)       5000        ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 1, 20)        0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 1, 20)       40          ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 1)           0           ['layer_normalization_7[0][0]']  \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 100)          200         ['global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 100)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 20)           2020        ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 20)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 1, 20)        0           ['dropout_7[0][0]',              \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 1, 20)       40          ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 1, 20)       5000        ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 1, 20)        0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 1, 20)       40          ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 1)           0           ['layer_normalization_9[0][0]']  \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 100)          200         ['global_average_pooling1d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 100)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 20)           2020        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 20)           0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 1, 20)        0           ['dropout_9[0][0]',              \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 1, 20)       40          ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 1, 20)       5000        ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 1, 20)        0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 1, 20)       40          ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 1)           0           ['layer_normalization_11[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 100)          200         ['global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 100)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 20)           2020        ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 20)           0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 1, 20)        0           ['dropout_11[0][0]',             \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 1, 20)       40          ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 1, 20)       5000        ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 1, 20)        0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 1, 20)       40          ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 1)           0           ['layer_normalization_13[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 100)          200         ['global_average_pooling1d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 100)          0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 20)           2020        ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 20)           0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 1, 20)        0           ['dropout_13[0][0]',             \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 1, 20)       40          ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 1, 20)       5000        ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 1, 20)        0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 1, 20)       40          ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 1)           0           ['layer_normalization_15[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 100)          200         ['global_average_pooling1d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 100)          0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 20)           2020        ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 20)           0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 1, 20)        0           ['dropout_15[0][0]',             \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 1)           0           ['add_15[0][0]']                 \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 2048)         4096        ['global_average_pooling1d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 2048)         0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1024)         2098176     ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 1024)         0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 500)          512500      ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 500)          0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 250)          125250      ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 250)          0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 100)          25100       ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 100)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 10)           1010        ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 10)           0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 1)            11          ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,824,563\n",
      "Trainable params: 2,824,563\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 804s 804s/step - loss: 1993.9744 - MSE: 4520531.0000 - RMSE: 2126.1541 - MAE: 1993.9744 - val_loss: 208.9702 - val_MSE: 51868.4844 - val_RMSE: 227.7465 - val_MAE: 208.9702\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1437s 1437s/step - loss: 1314.8856 - MSE: 2789204.0000 - RMSE: 1670.0911 - MAE: 1314.8856 - val_loss: 3891.7310 - val_MSE: 15243064.0000 - val_RMSE: 3904.2366 - val_MAE: 3891.7310\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1084s 1084s/step - loss: 1802.4139 - MSE: 4163425.0000 - RMSE: 2040.4473 - MAE: 1802.4139 - val_loss: 2267.0249 - val_MSE: 5184468.5000 - val_RMSE: 2276.9429 - val_MAE: 2267.0249\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1076s 1076s/step - loss: 1385.7869 - MSE: 2601981.7500 - RMSE: 1613.0659 - MAE: 1385.7869 - val_loss: 733.6157 - val_MSE: 552779.2500 - val_RMSE: 743.4913 - val_MAE: 733.6157\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 981s 981s/step - loss: 1205.5374 - MSE: 2505605.0000 - RMSE: 1582.9103 - MAE: 1205.5374 - val_loss: 306.3905 - val_MSE: 103257.8438 - val_RMSE: 321.3376 - val_MAE: 306.3905\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1209s 1209s/step - loss: 1303.4867 - MSE: 2763104.0000 - RMSE: 1662.2587 - MAE: 1303.4867 - val_loss: 511.9083 - val_MSE: 273757.0938 - val_RMSE: 523.2180 - val_MAE: 511.9083\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1075s 1075s/step - loss: 1246.8495 - MSE: 2628450.2500 - RMSE: 1621.2496 - MAE: 1246.8495 - val_loss: 1042.9113 - val_MSE: 1106911.3750 - val_RMSE: 1052.0985 - val_MAE: 1042.9113\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1126s 1126s/step - loss: 1188.2063 - MSE: 2412691.0000 - RMSE: 1553.2839 - MAE: 1188.2063 - val_loss: 1578.4387 - val_MSE: 2520561.2500 - val_RMSE: 1587.6276 - val_MAE: 1578.4387\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 968s 968s/step - loss: 1232.9724 - MSE: 2369343.0000 - RMSE: 1539.2671 - MAE: 1232.9724 - val_loss: 1568.0037 - val_MSE: 2487514.2500 - val_RMSE: 1577.1855 - val_MAE: 1568.0037\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1003s 1003s/step - loss: 1234.5190 - MSE: 2369201.5000 - RMSE: 1539.2211 - MAE: 1234.5190 - val_loss: 1200.1820 - val_MSE: 1462340.2500 - val_RMSE: 1209.2726 - val_MAE: 1200.1820\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1095s 1095s/step - loss: 1191.5979 - MSE: 2367177.2500 - RMSE: 1538.5634 - MAE: 1191.5979 - val_loss: 771.1018 - val_MSE: 609708.0625 - val_RMSE: 780.8381 - val_MAE: 771.1018\n",
      "Epoch 12/100\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "training = train_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
