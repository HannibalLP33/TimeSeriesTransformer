{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "from tensorflow.keras.layers import Lambda, Reshape, Concatenate, Add, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D, Layer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "logging.basicConfig(filename = \"logs.log\", format = \"%(asctime)s -- %(message)s\", datefmt='%m/%d/%Y %I:%M:%S %p', level = logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load_Data ###\n",
    "training_data = pd.read_csv(\"training_data/10sequence.csv\")\n",
    "training_data.head()\n",
    "X = training_data.iloc[:,:10]\n",
    "y = training_data.iloc[:,10]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = False)\n",
    "\n",
    "logging.info(\"Dataset Upload successfully\")\n",
    "logging.info(f\"X training set shape:{X_train.shape}\")\n",
    "logging.info(f\"y training set shape:{y_train.shape}\")\n",
    "logging.info(f\"X test set shape:{X_test.shape}\")\n",
    "logging.info(f\"y test set shape:{y_test.shape}\")\n",
    "\n",
    "\n",
    "print(\"Dataset Upload successfully\")\n",
    "print(f\"X training set shape:{X_train.shape}\")\n",
    "print(f\"y training set shape:{y_train.shape}\")\n",
    "print(f\"X test set shape:{X_test.shape}\")\n",
    "print(f\"y test set shape:{y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Global Variables ####\n",
    "sequence_len = 10 # Looking at 24 hours worth of data to determine\n",
    "epochs = 100\n",
    "attention_heads = 6\n",
    "projection_dim = sequence_len\n",
    "dropout = 0.1\n",
    "num_transformer_blocks = 8\n",
    "mlp_units = [2048, 1024, 500, 250, 100, 10]\n",
    "tranformer_mlp_units = [projection_dim ** 2, projection_dim * 2]\n",
    "\n",
    "\n",
    "X_train = tf.expand_dims(X_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert time to a vector that can be encoded to the features ###\n",
    "class Time2Vector(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernal: int = 64):\n",
    "        super().__init__(trainable = True,  name = \"Time2VecLayer\")\n",
    "        self.kernal = kernal - 1\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        ### Time to Vector Piecewise function ###\n",
    "        \n",
    "        self.weights_linear = self.add_weight(shape = (input_shape[1],1), initializer = \"uniform\", trainable = True, name = \"weights_linear\")\n",
    "        \n",
    "        self.bias_linear = self.add_weight(shape = (input_shape[1],1), initializer = \"uniform\", trainable = True, name = \"bias_linear\")\n",
    "        \n",
    "        self.weights_periodic = self.add_weight(shape = (input_shape[1], self.kernal), initializer = \"uniform\", trainable = True, name = \"weights_periodic\")\n",
    "        \n",
    "        self.bias_periodic = self.add_weight(shape = (input_shape[1], self.kernal), initializer = \"uniform\", trainable = True, name = \"bias_periodic\")\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = tf.expand_dims(x[:,:,0], axis = -1)\n",
    "        time_linear = (self.weights_linear * x) + self.bias_linear\n",
    "        # time_linear = tf.expand_dims(time_linear, axis = -1) #Expand dimensions to concat later\n",
    "        \n",
    "        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "        # time_periodic = tf.expand_dims(time_periodic, axis = -1)\n",
    "        \n",
    "        final_product = tf.concat([time_linear, time_periodic], axis = -1)\n",
    "        # final_product = tf.expand_dims(final_product, axis = 0)\n",
    "        return final_product\n",
    "    \n",
    "###Test Input###    \n",
    "test_input = tf.random.uniform(shape = (5000, 1, 10), dtype = tf.float32)\n",
    "exampleTV = Time2Vector(10)(test_input)\n",
    "exampleTV\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mlp_block(x, units):\n",
    "    x = GlobalAveragePooling1D(data_format = \"channels_first\")(x)\n",
    "    for unit in units:\n",
    "        x = Dense(unit, activation = tf.nn.gelu)(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "    return x\n",
    "def transformer_encoder(inputs, attention_heads, projection_dim, dropout):\n",
    "    ### Layer Normalization / Multihead Attention Layers ###\n",
    "    x = LayerNormalization(epsilon = 1e-6)(inputs)\n",
    "    x = MultiHeadAttention(num_heads = attention_heads, key_dim = projection_dim, dropout = dropout)(x,x)\n",
    "    skip1 = Add()([x, inputs])\n",
    "    \n",
    "    ### Feed Forward ###\n",
    "    x = LayerNormalization(epsilon = 1e-6)(skip1)\n",
    "    x = mlp_block(x, tranformer_mlp_units)\n",
    "    skip2 = Add()([x,skip1])\n",
    "    \n",
    "    return skip2\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    input = Input(shape = X_train.shape[1:]) # (Batch_size, Sequence Length, Number of Features)\n",
    "    x = Time2Vector(sequence_len)(input)\n",
    "    x = Concatenate(axis = -1)([input, x]) \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, attention_heads, projection_dim, dropout)\n",
    "    x = mlp_block(x, mlp_units)\n",
    "    output = Dense(1, activation = \"relu\")(x)\n",
    "    \n",
    "    model = Model(inputs = input, outputs = output)\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model):\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=1e-3, decay = 1e-4)\n",
    "    checkpoint_path = \"/models/\"\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss = tf.keras.losses.MeanAbsoluteError(), \n",
    "                  metrics = [tf.keras.metrics.MeanSquaredError(name = \"MSE\"), \n",
    "                             tf.keras.metrics.RootMeanSquaredError(name = \"RMSE\"),\n",
    "                             tf.keras.metrics.MeanAbsoluteError(name = \"MAE\")])\n",
    "    \n",
    "    history = model.fit(\n",
    "        x = X_train,\n",
    "        y = y_train,\n",
    "        epochs = epochs,\n",
    "        batch_size = X_train.shape[0],\n",
    "        validation_split = 0.2\n",
    "        \n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "training = train_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
